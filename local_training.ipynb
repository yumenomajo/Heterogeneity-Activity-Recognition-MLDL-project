{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 17:02:14.755150: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-12 17:02:14.771336: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-12 17:02:14.790918: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-12 17:02:14.796746: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-12 17:02:14.811655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: True\n",
      "(451162, 600), (112790, 600), (451162, 1), (112790, 1)\n"
     ]
    }
   ],
   "source": [
    "# %% Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf  # Only using TensorFlow 2.x\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Ensure eager execution is enabled\n",
    "print(\"Eager execution:\", tf.executing_eagerly())\n",
    "\n",
    "X_train = pd.read_csv(\"./x_train.csv\").values\n",
    "X_test = pd.read_csv(\"./x_test.csv\").values\n",
    "y_train = pd.read_csv(\"./y_train.csv\").values\n",
    "y_test = pd.read_csv(\"./y_test.csv\").values\n",
    "# %% Print the shape of training and testing data\n",
    "print(f\"{X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}\")\n",
    "\n",
    "# %% Define the number of hidden units, time steps, and features\n",
    "N_HIDDEN_UNITS = 64\n",
    "N_TIME_STEPS = 200\n",
    "N_FEATURES = 3\n",
    "\n",
    "\n",
    "\n",
    "# %% Reshape the training and testing data to match the LSTM input shape\n",
    "X_train = X_train.reshape(len(X_train), N_TIME_STEPS, N_FEATURES)\n",
    "X_test = X_test.reshape(len(X_test), N_TIME_STEPS, N_FEATURES)\n",
    "\n",
    "# %% Fill missing values and encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train.ravel())\n",
    "y_test_encoded = label_encoder.transform(y_test.ravel())\n",
    "\n",
    "# Update N_CLASSES\n",
    "N_CLASSES = len(label_encoder.classes_)\n",
    "\n",
    "# Ensure labels are in integer type\n",
    "y_train_encoded = y_train_encoded.astype('int32')\n",
    "y_test_encoded = y_test_encoded.astype('int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import necessary libraries for decision tree and random forest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %% Reshape the training and testing data for traditional machine learning\n",
    "# Reshape X_train and X_test to 2D arrays: (samples, time_steps * N_FEATURES)\n",
    "X_train_flattened = X_train.reshape(len(X_train), -1)\n",
    "X_test_flattened = X_test.reshape(len(X_test), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import necessary libraries for decision tree and random forest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %% Reshape the training and testing data for traditional machine learning\n",
    "# Reshape X_train and X_test to 2D arrays: (samples, time_steps * N_FEATURES)\n",
    "X_train_flattened = X_train.reshape(len(X_train), -1)\n",
    "X_test_flattened = X_test.reshape(len(X_test), -1)\n",
    "\n",
    "# %% Train a Decision Tree Classifier\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "decision_tree_model.fit(X_train_flattened, y_train_encoded)\n",
    "\n",
    "# %% Make predictions with Decision Tree model\n",
    "y_pred_dt = decision_tree_model.predict(X_test_flattened)\n",
    "\n",
    "# %% Evaluate Decision Tree model\n",
    "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
    "print(\"Decision Tree Classifier Accuracy:\", accuracy_dt)\n",
    "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))\n",
    "conf_matrix_dt = confusion_matrix(y_test_encoded, y_pred_dt)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_dt, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Confusion Matrix - Decision Tree\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存决策树模型\n",
    "joblib.dump(decision_tree_model, 'decision_tree_model.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存决策树模型\n",
    "joblib.dump(decision_tree_model, 'decision_tree_model.pkl')\n",
    "\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载模型\n",
    "loaded_dt_model = joblib.load('decision_tree_model.pkl')\n",
    "\n",
    "# 检查模型结构（可选）\n",
    "print(loaded_dt_model)\n",
    "\n",
    "# 验证加载是否成功：使用测试集进行预测\n",
    "try:\n",
    "    y_pred_loaded_dt = loaded_dt_model.predict(X_test_flattened)  # 使用测试集\n",
    "    print(\"Model loaded and predictions made successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error during model loading or prediction:\", e)\n",
    "\n",
    "# 如果有真实标签 y_test_encoded，可以计算准确率验证模型效果\n",
    "accuracy_loaded_model = accuracy_score(y_test_encoded, y_pred_loaded_dt)\n",
    "print(f\"Loaded Model Accuracy: {accuracy_loaded_model:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Train a Random Forest Classifier\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "random_forest_model.fit(X_train_flattened, y_train_encoded)\n",
    "\n",
    "# %% Make predictions with Random Forest model\n",
    "y_pred_rf = random_forest_model.predict(X_test_flattened)\n",
    "\n",
    "# %% Evaluate Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test_encoded, y_pred_rf)\n",
    "print(\"Random Forest Classifier Accuracy:\", accuracy_rf)\n",
    "print(classification_report(y_test_encoded, y_pred_rf, target_names=label_encoder.classes_))\n",
    "conf_matrix_rf = confusion_matrix(y_test_encoded, y_pred_rf)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(decision_tree_model, 'random_forest_model.pkl')\n",
    "\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载模型\n",
    "loaded_dt_model = joblib.load('random_forest_model.pkl')\n",
    "\n",
    "# 检查模型结构（可选）\n",
    "print(loaded_dt_model)\n",
    "\n",
    "# 验证加载是否成功：使用测试集进行预测\n",
    "try:\n",
    "    y_pred_loaded_dt = loaded_dt_model.predict(X_test_flattened)  # 使用测试集\n",
    "    print(\"Model loaded and predictions made successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error during model loading or prediction:\", e)\n",
    "\n",
    "# 如果有真实标签 y_test_encoded，可以计算准确率验证模型效果\n",
    "accuracy_loaded_model = accuracy_score(y_test_encoded, y_pred_loaded_dt)\n",
    "print(f\"Loaded Model Accuracy: {accuracy_loaded_model:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# %% Train an XGBoost Classifier\n",
    "xgboost_model = xgb.XGBClassifier(n_estimators=100, random_state=RANDOM_SEED, use_label_encoder=False, eval_metric='logloss')\n",
    "xgboost_model.fit(X_train_flattened, y_train_encoded)\n",
    "\n",
    "# %% Make predictions with XGBoost model\n",
    "y_pred_xgb = xgboost_model.predict(X_test_flattened)\n",
    "\n",
    "# %% Evaluate XGBoost model\n",
    "accuracy_xgb = accuracy_score(y_test_encoded, y_pred_xgb)\n",
    "print(\"XGBoost Classifier Accuracy:\", accuracy_xgb)\n",
    "print(classification_report(y_test_encoded, y_pred_xgb, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_xgb = confusion_matrix(y_test_encoded, y_pred_xgb)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_xgb, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Confusion Matrix - XGBoost\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(decision_tree_model, 'xgboost_model.pkl')\n",
    "\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载模型\n",
    "loaded_dt_model = joblib.load('xgboost_model.pkl')\n",
    "\n",
    "# 检查模型结构（可选）\n",
    "print(loaded_dt_model)\n",
    "\n",
    "# 验证加载是否成功：使用测试集进行预测\n",
    "try:\n",
    "    y_pred_loaded_dt = loaded_dt_model.predict(X_test_flattened)  # 使用测试集\n",
    "    print(\"Model loaded and predictions made successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error during model loading or prediction:\", e)\n",
    "\n",
    "# 如果有真实标签 y_test_encoded，可以计算准确率验证模型效果\n",
    "accuracy_loaded_model = accuracy_score(y_test_encoded, y_pred_loaded_dt)\n",
    "print(f\"Loaded Model Accuracy: {accuracy_loaded_model:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# %% Train a LightGBM Classifier\n",
    "lightgbm_model = lgb.LGBMClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "lightgbm_model.fit(X_train_flattened, y_train_encoded)\n",
    "\n",
    "# %% Make predictions with LightGBM model\n",
    "y_pred_lgb = lightgbm_model.predict(X_test_flattened)\n",
    "\n",
    "# %% Evaluate LightGBM model\n",
    "accuracy_lgb = accuracy_score(y_test_encoded, y_pred_lgb)\n",
    "print(\"LightGBM Classifier Accuracy:\", accuracy_lgb)\n",
    "print(classification_report(y_test_encoded, y_pred_lgb, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_lgb = confusion_matrix(y_test_encoded, y_pred_lgb)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_lgb, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Confusion Matrix - LightGBM\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(decision_tree_model, 'lightgbm_model.pkl')\n",
    "\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载模型\n",
    "loaded_dt_model = joblib.load('lightgbm_model.pkl')\n",
    "\n",
    "# 检查模型结构（可选）\n",
    "print(loaded_dt_model)\n",
    "\n",
    "# 验证加载是否成功：使用测试集进行预测\n",
    "try:\n",
    "    y_pred_loaded_dt = loaded_dt_model.predict(X_test_flattened)  # 使用测试集\n",
    "    print(\"Model loaded and predictions made successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error during model loading or prediction:\", e)\n",
    "\n",
    "# 如果有真实标签 y_test_encoded，可以计算准确率验证模型效果\n",
    "accuracy_loaded_model = accuracy_score(y_test_encoded, y_pred_loaded_dt)\n",
    "print(f\"Loaded Model Accuracy: {accuracy_loaded_model:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试模型\n",
    "# 假设已经训练好的 XGBoost 模型\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 准备测试数据（已加载 X_test_flattened 和 y_test_encoded）\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)  # 假设 y_train 是训练时的标签\n",
    "y_test_encoded = label_encoder.transform(y_test)  # 确保测试标签被编码\n",
    "\n",
    "X_train_flattened = X_train.reshape(len(X_train), -1)\n",
    "X_test_flattened = X_test.reshape(len(X_test), -1)\n",
    "\n",
    "# 调用函数进行评估\n",
    "accuracy = evaluate_model(\n",
    "    model=decision_tree_model,                # 已训练的 XGBoost 模型\n",
    "    X_test=X_test_flattened,            # 测试集特征\n",
    "    y_test=y_test,                      # 测试集标签（未编码）\n",
    "    label_encoder=label_encoder,        # 标签编码器\n",
    "    history=None                        # XGBoost 无训练历史，传 None\n",
    ")\n",
    "\n",
    "# 输出最终的测试集准确率\n",
    "print(f\"Final Test Accuracy with XGBoost: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %% Define the custom LSTM model class\n",
    "class CustomLSTMModel(tf.keras.Model):\n",
    "    def __init__(self, N_FEATURES, N_HIDDEN_UNITS, N_CLASSES, **kwargs):\n",
    "        super(CustomLSTMModel, self).__init__(**kwargs)\n",
    "        # Initialize weights and biases\n",
    "        self.N_FEATURES = N_FEATURES\n",
    "        self.N_HIDDEN_UNITS = N_HIDDEN_UNITS\n",
    "        self.N_CLASSES = N_CLASSES\n",
    "        \n",
    "        self.W_hidden = tf.Variable(tf.random.normal([N_FEATURES, N_HIDDEN_UNITS]), trainable=True, name=\"W_hidden\")\n",
    "        self.b_hidden = tf.Variable(tf.random.normal([N_HIDDEN_UNITS], mean=1.0), trainable=True, name=\"b_hidden\")\n",
    "        \n",
    "        self.W_output = tf.Variable(tf.random.normal([N_HIDDEN_UNITS, N_CLASSES]), trainable=True, name=\"W_output\")\n",
    "        self.b_output = tf.Variable(tf.random.normal([N_CLASSES]), trainable=True, name=\"b_output\")\n",
    "        \n",
    "        # Define two LSTM layers\n",
    "        self.lstm_layers = [tf.keras.layers.LSTMCell(N_HIDDEN_UNITS) for _ in range(2)]\n",
    "        self.rnn = tf.keras.layers.RNN(self.lstm_layers, return_sequences=True, return_state=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        time_steps = tf.shape(inputs)[1]\n",
    "        features = tf.shape(inputs)[2]\n",
    "        \n",
    "        X = tf.transpose(inputs, [1, 0, 2])  # (time_steps, batch_size, features)\n",
    "        X = tf.reshape(X, [-1, features])    # (time_steps * batch_size, features)\n",
    "        \n",
    "        # Compute hidden layer\n",
    "        hidden = tf.nn.relu(tf.matmul(X, self.W_hidden) + self.b_hidden)  # (time_steps * batch_size, hidden_units)\n",
    "        hidden = tf.reshape(hidden, [time_steps, batch_size, self.N_HIDDEN_UNITS])  # (time_steps, batch_size, hidden_units)\n",
    "        hidden = tf.transpose(hidden, [1, 0, 2])  # (batch_size, time_steps, hidden_units)\n",
    "        \n",
    "        # Pass through LSTM layers\n",
    "        outputs, *states = self.rnn(hidden)  # outputs: (batch_size, time_steps, hidden_units)\n",
    "        \n",
    "        # Get output from the last time step\n",
    "        lstm_last_output = outputs[:, -1, :]  # (batch_size, hidden_units)\n",
    "        \n",
    "        # Compute the final output\n",
    "        logits = tf.matmul(lstm_last_output, self.W_output) + self.b_output  # (batch_size, num_classes)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    def get_config(self):\n",
    "    # 不调用 super().get_config()，直接返回当前模型的配置即可\n",
    "        config = {\n",
    "            \"N_FEATURES\": self.N_FEATURES,\n",
    "            \"N_HIDDEN_UNITS\": self.N_HIDDEN_UNITS,\n",
    "            \"N_CLASSES\": self.N_CLASSES\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # 从配置字典中恢复模型实例\n",
    "        return cls(\n",
    "            N_FEATURES=config['N_FEATURES'],\n",
    "            N_HIDDEN_UNITS=config['N_HIDDEN_UNITS'],\n",
    "            N_CLASSES=config['N_CLASSES']\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Instantiate the model\n",
    "model = CustomLSTMModel(N_FEATURES, N_HIDDEN_UNITS, N_CLASSES)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# %% Print the data shape to ensure everything matches\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train_encoded shape: {y_train_encoded.shape}\")\n",
    "print(f\"Unique labels: {np.unique(y_train_encoded)}\")\n",
    "print(f\"N_CLASSES: {N_CLASSES}\")\n",
    "\n",
    "# %% Train the model\n",
    "history = model.fit(X_train, y_train_encoded, batch_size=64, epochs=10, validation_data=(X_test, y_test_encoded), verbose=1)\n",
    "\n",
    "# %% Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# %% Freeze the layers (if needed)\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.LSTM):\n",
    "        layer.trainable = False\n",
    "\n",
    "# Recompile the model after freezing layers\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# %% Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test_encoded), yticklabels=np.unique(y_test_encoded))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# %% Visualize training and validation metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy and loss for training and validation\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_lstm = accuracy_score(y_test_encoded, y_pred_classes)\n",
    "print(\"LSTM Accuracy:\", accuracy_lstm)\n",
    "print(classification_report(y_test_encoded,y_pred_classes, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save('my_custom_lstm_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# 自定义对象字典\n",
    "custom_objects = {'CustomLSTMModel': CustomLSTMModel}\n",
    "\n",
    "# 读取模型\n",
    "loaded_model = load_model('my_custom_lstm_model.keras', custom_objects=custom_objects)\n",
    "\n",
    "# 验证模型加载成功\n",
    "print(loaded_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# 全局参数\n",
    "N_TIME_STEPS = 200  # 时间窗口大小\n",
    "N_FEATURES = 3  # 每个时间步的特征数量\n",
    "OUTPUT_DIR = \"./experiment_results\"  # 保存结果的目录\n",
    "\n",
    "# 创建结果目录\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 数据集路径\n",
    "datasets = [\n",
    "    (\"devicenexus4_1_x.csv\", \"devicenexus4_1_y.csv\"),\n",
    "    (\"devicenexus4_2_x.csv\", \"devicenexus4_2_y.csv\"),\n",
    "    (\"devices3_1_x.csv\", \"devices3_1_y.csv\"),\n",
    "    (\"devices3_2_x.csv\", \"devices3_2_y.csv\"),\n",
    "    (\"devices3mini_1_x.csv\", \"devices3mini_1_y.csv\"),\n",
    "    (\"devices3mini_2_x.csv\", \"devices3mini_2_y.csv\"),\n",
    "    (\"devicesamsungold_1_x.csv\", \"devicesamsungold_1_y.csv\"),\n",
    "    (\"devicesamsungold_2_x.csv\", \"devicesamsungold_2_y.csv\"),\n",
    "]\n",
    "\n",
    "# 单个数据集评估函数\n",
    "def evaluate_dataset(model, file_x, file_y, label_encoder, output_dir):\n",
    "    \"\"\"\n",
    "    评估单个数据集并保存结果到文件。\n",
    "\n",
    "    Parameters:\n",
    "    - model: 已训练好的模型\n",
    "    - file_x: 特征文件路径\n",
    "    - file_y: 标签文件路径\n",
    "    - label_encoder: 标签编码器\n",
    "    - output_dir: 保存结果的目录\n",
    "    \"\"\"\n",
    "    # 加载数据\n",
    "    X_test = pd.read_csv(file_x).values\n",
    "    y_test = pd.read_csv(file_y).values\n",
    "    X_test = X_test.reshape(len(X_test), N_TIME_STEPS, N_FEATURES)  # 保持时间步特征维度\n",
    "\n",
    "    # 编码标签\n",
    "    y_test_encoded = label_encoder.transform(y_test.ravel())\n",
    "\n",
    "    # 模型预测\n",
    "    y_pred = model.predict(X_test)  # 无需展平\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
    "\n",
    "    # 分类报告\n",
    "    report = classification_report(y_test_encoded, y_pred_classes, target_names=label_encoder.classes_)\n",
    "    print(f\"Classification Report for {file_x}:\\n{report}\")\n",
    "\n",
    "    # 保存分类报告到文本文件\n",
    "    report_file = os.path.join(output_dir, f\"{os.path.basename(file_x)}_report.txt\")\n",
    "    with open(report_file, \"w\") as f:\n",
    "        f.write(f\"Classification Report for {file_x}\\n\")\n",
    "        f.write(report)\n",
    "        f.write(f\"\\nAccuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "    # 混淆矩阵\n",
    "    cm = confusion_matrix(y_test_encoded, y_pred_classes)\n",
    "\n",
    "    # 绘制混淆矩阵并保存为图片\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title(f\"Confusion Matrix for {file_x}\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.tight_layout()\n",
    "    cm_image_file = os.path.join(output_dir, f\"{os.path.basename(file_x)}_confusion_matrix.png\")\n",
    "    plt.savefig(cm_image_file)\n",
    "    plt.close()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设已训练的模型和训练集标签\n",
    "  # 替换为您的已训练模型\n",
    "y_train = pd.read_csv(\"y_train.csv\").values  # 替换为您的训练标签文件\n",
    "\n",
    "# 初始化标签编码器\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train.ravel())  # 使用训练集标签 fit 编码器\n",
    "\n",
    "# 保存实验结果汇总\n",
    "summary_file = os.path.join(OUTPUT_DIR, \"experiment_summary.txt\")\n",
    "results = {}\n",
    "with open(summary_file, \"w\") as summary:\n",
    "    for file_x, file_y in datasets:\n",
    "        print(f\"Evaluating dataset: {file_x}\")\n",
    "        accuracy = evaluate_dataset(model, file_x, file_y, label_encoder, OUTPUT_DIR)\n",
    "        results[file_x] = accuracy\n",
    "        summary.write(f\"{file_x}: {accuracy:.4f}\\n\")\n",
    "\n",
    "    # 打印总结\n",
    "print(\"\\nSummary of Experiment Results:\")\n",
    "for dataset, accuracy in results.items():\n",
    "    print(f\"{dataset}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码展示了一个 **自定义 LSTM 模型** 的实现，并且在模型保存和加载的过程中使用了一些 Keras 框架的高级特性。为了更好地理解其使用的方法，我们可以从几个角度来分析：**模型设计**、**模型保存和加载**、以及 **自定义层的序列化与反序列化**。\n",
    "\n",
    "### 1. **模型设计：使用自定义层**\n",
    "\n",
    "这段代码定义了一个自定义的 LSTM 模型，继承自 `tf.keras.Model`，并实现了以下内容：\n",
    "\n",
    "- **自定义初始化方法（`__init__`）**：\n",
    "  在 `__init__` 方法中，定义了网络的核心结构，包括：\n",
    "  - **权重和偏置**：使用 `tf.Variable` 初始化了两组参数 `W_hidden` 和 `b_hidden`，用于隐藏层的线性变换；`W_output` 和 `b_output` 用于输出层的线性变换。这些权重参数的初始化是随机的，并且设置了 `trainable=True`，表示这些参数将在训练过程中优化。\n",
    "  \n",
    "  - **LSTM 层**：通过定义 `tf.keras.layers.LSTMCell` 创建了两个 LSTM 单元，并将它们组合成一个 RNN 层。LSTM 单元通常用于处理时序数据，因为它们能够在序列的每个时间步捕捉数据的上下文信息。这个模型在 `call()` 方法中处理输入数据并通过 RNN 层进行处理。\n",
    "\n",
    "  - **传递 `trainable` 参数**：在 `__init__` 方法中，参数（如权重矩阵）被标记为 `trainable=True`，表示它们将在训练过程中进行更新。\n",
    "\n",
    "### 2. **`call()` 方法：定义前向传播逻辑**\n",
    "\n",
    "`call()` 方法定义了如何通过模型的网络结构进行前向传播：\n",
    "\n",
    "- **输入数据的维度转换**：输入数据首先被转换为 `[time_steps, batch_size, features]` 的形状，并进行重塑和转置。`X = tf.transpose(inputs, [1, 0, 2])` 将数据的时间步转置到第一个维度。\n",
    "  \n",
    "- **计算隐藏层输出**：计算隐藏层的激活输出 `hidden`，并通过 `relu` 激活函数进行非线性变换。`hidden` 是通过线性变换计算得到的，并且通过 `tf.matmul()` 计算隐藏状态。\n",
    "\n",
    "- **LSTM 层输出**：`self.rnn(hidden)` 将数据传递给 LSTM 层，得到输出和隐状态。这是一个深度 RNN（即多层 RNN），每层都是一个 LSTM 单元。\n",
    "\n",
    "- **输出计算**：从 LSTM 的最后一个时间步获取输出，并通过权重矩阵 `W_output` 和偏置 `b_output` 计算最终的 logits 输出，用于分类。\n",
    "\n",
    "### 3. **自定义层的序列化与反序列化**\n",
    "\n",
    "这段代码特别关注了如何保存和加载模型时，能够正确地处理自定义层和自定义参数。这是通过重写 `get_config()` 和 `from_config()` 方法来实现的。\n",
    "\n",
    "#### 3.1 `get_config()` 方法\n",
    "\n",
    "`get_config()` 方法是 Keras 模型的标准方法，用于返回模型的配置字典。该字典包含了模型的所有超参数，以便能够正确地将模型保存和加载。\n",
    "\n",
    "- 在 `get_config()` 方法中，我们首先调用 `super(CustomLSTMModel, self).get_config()` 获取父类的配置（即 `tf.keras.Model` 的配置），然后通过 `config.update({...})` 更新模型的自定义配置（如 `N_FEATURES`, `N_HIDDEN_UNITS`, `N_CLASSES`）。这确保了这些重要的超参数也被包含在内。\n",
    "\n",
    "#### 3.2 `from_config()` 方法\n",
    "\n",
    "`from_config()` 是一个类方法（即通过 `cls` 引用类本身），它负责根据 `get_config()` 返回的配置字典重新构建模型实例。\n",
    "\n",
    "- 在 `from_config()` 方法中，我们从配置字典中提取出模型需要的超参数（`N_FEATURES`, `N_HIDDEN_UNITS`, `N_CLASSES`），然后用这些参数创建一个新的模型实例。\n",
    "  \n",
    "  通过这种方式，在模型加载时，Keras 会使用这个方法来恢复模型的结构，而不仅仅是加载模型的权重。\n",
    "\n",
    "### 4. **Keras 序列化机制：保存和加载模型**\n",
    "\n",
    "Keras 提供了强大的序列化和反序列化功能，使得你可以保存整个模型（包括网络结构和权重）并在稍后加载。保存和加载模型时，Keras 使用了以下几个关键步骤：\n",
    "\n",
    "- **保存模型**：`model.save('path_to_model.h5')` 保存了模型的结构和权重。这里 `.h5` 格式是 HDF5 格式，常用于存储深度学习模型。\n",
    "  \n",
    "- **加载模型时的自定义对象处理**：加载时，如果模型中包含了自定义层（如 `CustomLSTMModel`），需要通过 `custom_objects` 参数将这些自定义类传递给 `load_model()`，这样 Keras 就能够识别并正确加载这些自定义层。`load_model('path_to_model.h5', custom_objects={'CustomLSTMModel': CustomLSTMModel})` 会使用 `CustomLSTMModel` 类来反序列化模型。\n",
    "\n",
    "#### 3.3 `trainable` 参数的处理\n",
    "\n",
    "在反序列化模型时，Keras 会将配置字典中的 `trainable` 参数传递给模型的层。由于我们在 `CustomLSTMModel` 中自定义了权重（`W_hidden`，`b_hidden`等）并指定了 `trainable=True`，这些权重在保存时会被标记为可训练。当加载模型时，`trainable` 的配置确保了这些参数依然是可训练的。\n",
    "\n",
    "### 5. **总结：使用的方法**\n",
    "\n",
    "在这段代码中，使用了以下主要的方法和设计模式：\n",
    "\n",
    "1. **自定义模型层**：通过继承 `tf.keras.Model` 创建了一个自定义的 LSTM 模型，手动定义了前向传播的逻辑。\n",
    "   \n",
    "2. **权重初始化**：使用 `tf.Variable` 手动初始化模型的权重和偏置，这些变量被设置为 `trainable=True`，使得它们能够在训练过程中更新。\n",
    "\n",
    "3. **模型序列化与反序列化**：\n",
    "   - `get_config()` 和 `from_config()` 方法用于保存和加载自定义模型层。\n",
    "   - 通过 `custom_objects` 传递自定义层，确保加载模型时可以正确反序列化自定义层和超参数。\n",
    "\n",
    "4. **Keras 保存与加载机制**：利用 `model.save()` 和 `load_model()` 实现模型的持久化和恢复。\n",
    "\n",
    "通过这些方法，代码实现了一个自定义的深度学习模型，并支持模型的保存和加载，确保自定义层能够被正确处理，同时保留了训练过程中的可训练参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Save the model after training\n",
    "model.save('trained_lstm_model.h5')  # This saves the entire model to a file\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('trained_lstm_model.h5')\n",
    "print(\"Model loaded from 'trained_lstm_model.h5'\")\n",
    "\n",
    "# %% Evaluate the loaded model on a new test set (X_test_new, y_test_new)\n",
    "# Make sure X_test_new and y_test_new are preprocessed similarly to your original data\n",
    "\n",
    "loss, accuracy = loaded_model.evaluate(X_test_new, y_test_new)\n",
    "print(f\"New Test Accuracy: {accuracy}\")\n",
    "\n",
    "# %% Confusion Matrix on the new test set\n",
    "y_pred_new = loaded_model.predict(X_test_new)\n",
    "y_pred_classes_new = np.argmax(y_pred_new, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Compute confusion matrix for the new test set\n",
    "cm_new = confusion_matrix(y_test_new, y_pred_classes_new)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_new, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test_new), yticklabels=np.unique(y_test_new))\n",
    "plt.title('Confusion Matrix on New Test Set')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
